# -*- coding: utf-8 -*-
"""hw1_ML_Q5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-F0f28Ls8PCiWrZmGyNsQqAJAn8w9Irh

Problem 5: Iris flowers | KNN

a) Load the Iris dataset from scikit-learn and split it into training and test sets using a 80/20 split. Use a random seed of 42 for reproducibility.
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load the Iris dataset
iris = load_iris()

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

# Print the shapes of the training and testing data sets
print("Training data shape: X =", X_train.shape, ", y =", y_train.shape)
print("Testing data shape: X =", X_test.shape, ", y =", y_test.shape)

"""we first load the Iris dataset from scikit-learn library using the load_iris function. Then, we split the data into training and test sets using the train_test_split function. The test_size argument is set to 0.2, which means that 20% of the data is used for testing, and the remaining 80% is used for training. We also set the random_state argument to 42 for reproducibility.

Finally, we print the shapes of the training and testing data sets to verify that they have been split properly. The training data consists of 120 samples and the test data consists of 30 samples, which is what we expect given the 80/20 split.

b) Preprocess the data by scaling the features to have zero mean and unit variance using the StandardScaler from scikit-learn.
"""

from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)

#checking the mean and standard deviation of the training and test data

print("Training data mean: ", X_train_scaled.mean(axis=0))
print("Training data std dev: ", X_train_scaled.std(axis=0))
print("Test data mean: ", X_test_scaled.mean(axis=0))
print("Test data std dev: ", X_test_scaled.std(axis=0))

"""we first import the StandardScaler from the sklearn.preprocessing module. Then, we initialize a scaler object of StandardScaler and fit it onto the training data using the fit method. This calculates the mean and variance of each feature in the training data.

We then use the transform method of the StandardScaler object to transform both the training and test data. This scales each feature to have zero mean and unit variance based on the values calculated from the training data.

After this preprocessing, the X_train and X_test variables contain the scaled training and test data, respectively.

As we can see, the mean values are close to zero and the standard deviations are close to one for both the training and test datasets. Therefore, the scaling has been applied correctly.

c) Train a KNN classifier on the training set using different values of K ranging from 1 to 20, and evaluate the performance of the classifier on the test set by computing the classification accuracy for each value of K. Choose the optimal value of K based on the accuracy results.
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Define the range of K values to test
k_values = range(1, 21)

# Initialize an empty list to store the accuracy scores for each K value
accuracy_scores = []

# Train a KNN classifier for each value of K and compute the accuracy score on the test set
for k in k_values:
    clf = KNeighborsClassifier(n_neighbors=k)
    clf.fit(X_train_scaled, y_train)
    y_pred = clf.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    print("K =", k, "accuracy =", accuracy)
    accuracy_scores.append(accuracy)

"""we first import the KNeighborsClassifier class and the accuracy_score function from the sklearn.neighbors and sklearn.metrics modules, respectively.

Then, we define the range of K values to test using the range function, which generates a sequence of integers from 1 to 20. We also initialize an empty list called accuracy_scores to store the accuracy scores for each value of K.

We then train a KNN classifier for each value of K using a for loop. Inside the loop, we create a new KNeighborsClassifier object with n_neighbors set to the current value of K, and then fit this classifier to the scaled training data using the fit method.

Next, we compute the predicted class labels for the test data using the predict method, and then compute the accuracy score for the classifier using the accuracy_score function, which takes the true class labels (y_test) and the predicted class labels (y_pred) as inputs.

For each value of K, we print out the accuracy score for the classifier. Finally, we append the accuracy score to the accuracy_scores list.

We can then plot the accuracy scores as a function of K to visualize the relationship between K and accuracy:
"""

import matplotlib.pyplot as plt

# Plot the accuracy scores as a function of K
plt.plot(k_values, accuracy_scores)
plt.xlabel("K")
plt.ylabel("Accuracy")
plt.title("KNN classifier accuracy")
plt.show()

"""As can be seen, the accuracy for all values between 1 and 20 is 100, which means that it does not seem normal. """