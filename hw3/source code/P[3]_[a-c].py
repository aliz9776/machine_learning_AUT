# -*- coding: utf-8 -*-
"""hw3-ML-Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r9rrL2h7nLmeGPeZdYqrkck4ry_VkCc6

**Problem 3: Sentiment Analysis**

Snappfood (an online food delivery company) user comments containing 70,000 comments with two labels: 1- Happy (Positive) 2- Sad (Negative). We want you to build naive bayes Classifier from scratch to perform sentiment analysis. (This link1 can be very useful). Follow the steps below:
"""

!pip install hazm

"""a) Before building the model, you must do the required text preprocessing. Explain all pre-processing steps. (You can use the hazm library, which is used to process the Persian language. (Note that this section has the highest score)."""

import csv
from hazm import *
import numpy as np
import re


normalizer = Normalizer()
lemmatizer = Lemmatizer()
tokenizer = WordTokenizer()

def preprocess(text):
    
    # Remove all punctuations except for dot and question mark
    text = re.sub(r'[^\w\sØŸ.]', '', text)
    
    # Normalize text
    text = normalizer.normalize(text)
    
    # Tokenize text
    words = tokenizer.tokenize(text)
    
    # Lemmatize words and remove stop words
    words = [lemmatizer.lemmatize(word) for word in words if not word in stopwords_list()]
    
    # Join the words back into a string
    text = ' '.join(words)
    
    return text

import tqdm

import pandas as pd
from hazm import word_tokenize
from hazm import Normalizer
from hazm import stopwords_list
from hazm import Stemmer

df = pd.read_csv('Snappfood - Sentiment Analysis.csv', delimiter='\t')

#Remove unnecessary column

df = df.drop('label_id', axis=1)

# remove the first column which is empty
df.drop(df.columns[0], axis=1, inplace=True)

#Convert the labels to numerical values:

label_to_id = {'HAPPY': 0, 'SAD': 1}
df['label'] = df['label'].map(label_to_id)

## Normalize the tokens using the hazm library

# Apply the normalization function to the comments column
normalizer = Normalizer()
df['comment'] = df['comment'].apply(normalizer.normalize)
print(df['comment'].head())

#Tokenize the comments using the hazm library
print(df['comment'].head())
df['comment'] = df['comment'].apply(word_tokenize)
print(df['comment'].head())

#Remove stop words using the hazm library

stopwords = stopwords_list()
df['comment'] = df['comment'].apply(lambda tokens: [token for token in tokens if token not in stopwords])
print(df['comment'].head())
#Stem the tokens using the hazm library

stemmer = Stemmer()
df['comment'] = df['comment'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])

print(df['comment'].head(10))

"""b) Building the naive bayes classifier. Explain how naive bayes is used for this problem."""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB

# Convert the list of tokenized words in 'comment' column to strings
df['comment'] = df['comment'].apply(lambda x: ' '.join(x))
print(df['comment'].head(10))
print(df.isnull().sum())
df.dropna(inplace=True)

# Convert preprocessed comments to numerical representation using TfidfVectorizer
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['comment'])

# Split the dataset into training and testing sets
train_size = int(len(df) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = df['label'][:train_size], df['label'][train_size:]

# Train the Naive Bayes classifier
clf = MultinomialNB()

"""c) Fitting the model on training set and evaluating accuracies on the test set."""

from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support



#fit classifier

clf.fit(X_train, y_train)

# Test the classifier
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

# Calculate precision, recall, and F1-score
precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average='weighted')

# Print results
print(f"Accuracy: {accuracy:.2f}")
print(f"Confusion Matrix:\n{conf_matrix}")
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)