# -*- coding: utf-8 -*-
"""HW2-ML-Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TQJcBXKltUr5HhnKc_-9Wk28ehEkvSEk

Problem 3: Use ML in your Field| Preprocessing Dataset

One of the goals of the machine learning course is for you to be able to apply the methods you have learned in your field. One of the most important tasks of a machine learning engineer is to be able to pre-process the dataset well and prepare it for applying machine learning and neural network methods. In this question, you need to find a data set related to your field and apply the pre-processes reviewed in the course on this data set. This data set should contain at least 70 data.

a) Describe the data set and explain its characteristics

The dataset contains 14,640 tweets from February 2015 that mention one of six major US airlines: American, Delta, Southwest, US Airways, United, and Virgin America. The tweets were originally collected and annotated by CrowdFlower (now known as Figure Eight) for a Kaggle competition on sentiment analysis.

Each tweet in the dataset has been labeled with one of three sentiment classes: positive, negative, or neutral. The sentiment labels were assigned by human annotators who were asked to classify the tweets based on their overall sentiment towards the airline mentioned in the tweet.

In addition to the text of the tweet and its sentiment label, the dataset includes other information such as the user's Twitter handle, the time of the tweet, the airline mentioned in the tweet, and the retweet count and favorite count of the tweet.

The characteristics of the dataset are:

Size: The dataset contains 14,640 tweets, which is a moderate-sized dataset for sentiment analysis tasks.

Sentiment distribution: The sentiment labels in the dataset are roughly balanced, with 4,915 positive tweets, 5,862 negative tweets, and 3,863 neutral tweets.

Class imbalance by airline: There is some class imbalance within the dataset when looking at the distribution of sentiment labels for each airline. For example, tweets about US Airways are more likely to be negative than tweets about other airlines.

Noisy data: Since the tweets were collected from Twitter, they may contain noise such as misspellings, slang, and other informal language. Additionally, some tweets may not actually express sentiment towards the airline mentioned in the tweet.

b) Load the selected data set and display the first seven data.
"""

import pandas as pd

# Load the dataset from CSV file
df = pd.read_csv("Tweets.csv")

# Display the first seven rows of the dataset
print(df.head(7))

"""b) Load the selected data set and display the first seven data."""

import nltk
nltk.download('punkt')

nltk.download("stopwords")

import pandas as pd
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

# Load the dataset from CSV file
df = pd.read_csv("Tweets.csv")

# Remove unnecessary columns
df = df.drop(columns=["tweet_id", "airline_sentiment_confidence", "negativereason_confidence"])

# Convert tweet text to lowercase
df["text"] = df["text"].str.lower()

# Remove URLs, mentions, and hashtags
df["text"] = df["text"].apply(lambda x: re.sub(r"http\S+", "", x))
df["text"] = df["text"].apply(lambda x: re.sub(r"@\S+", "", x))
df["text"] = df["text"].apply(lambda x: re.sub(r"#\S+", "", x))

# Remove punctuation and special characters
df["text"] = df["text"].str.replace('[^\w\s]','')

# Tokenize tweet text
df["tokens"] = df["text"].apply(lambda x: word_tokenize(x))

# Remove stop words
stop_words = set(stopwords.words("english"))
df["tokens"] = df["tokens"].apply(lambda x: [word for word in x if not word in stop_words])

# Display the pre-processed data
print(df.head(7))

"""d) Teach a model using one of the methods learned in the lesson."""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df["text"], df["airline_sentiment"], test_size=0.2, random_state=42)

# Convert text data to a numerical feature matrix
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a Naive Bayes classifier
clf = MultinomialNB()
clf.fit(X_train_vec, y_train)

"""e) Evaluate the model."""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Evaluate the model and print the metrics
y_pred = clf.predict(X_test_vec)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 score:", f1)