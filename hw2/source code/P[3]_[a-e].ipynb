{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3: Use ML in your Field| Preprocessing Dataset"
      ],
      "metadata": {
        "id": "CxY4oq08UbMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the goals of the machine learning course is for you to be able to apply the methods you have learned in your field. One of the most important tasks of a machine learning engineer is to be able to pre-process the dataset well and prepare it for applying machine learning and neural network methods. In this question, you need to find a data set related to your field and apply the pre-processes reviewed in the course on this data set. This data set should contain at least 70 data."
      ],
      "metadata": {
        "id": "vJuDt8bFuwLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Describe the data set and explain its characteristics"
      ],
      "metadata": {
        "id": "Q-F4x9PbHFWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 14,640 tweets from February 2015 that mention one of six major US airlines: American, Delta, Southwest, US Airways, United, and Virgin America. The tweets were originally collected and annotated by CrowdFlower (now known as Figure Eight) for a Kaggle competition on sentiment analysis.\n",
        "\n",
        "Each tweet in the dataset has been labeled with one of three sentiment classes: positive, negative, or neutral. The sentiment labels were assigned by human annotators who were asked to classify the tweets based on their overall sentiment towards the airline mentioned in the tweet.\n",
        "\n",
        "In addition to the text of the tweet and its sentiment label, the dataset includes other information such as the user's Twitter handle, the time of the tweet, the airline mentioned in the tweet, and the retweet count and favorite count of the tweet.\n",
        "\n",
        "The characteristics of the dataset are:\n",
        "\n",
        "Size: The dataset contains 14,640 tweets, which is a moderate-sized dataset for sentiment analysis tasks.\n",
        "\n",
        "Sentiment distribution: The sentiment labels in the dataset are roughly balanced, with 4,915 positive tweets, 5,862 negative tweets, and 3,863 neutral tweets.\n",
        "\n",
        "Class imbalance by airline: There is some class imbalance within the dataset when looking at the distribution of sentiment labels for each airline. For example, tweets about US Airways are more likely to be negative than tweets about other airlines.\n",
        "\n",
        "Noisy data: Since the tweets were collected from Twitter, they may contain noise such as misspellings, slang, and other informal language. Additionally, some tweets may not actually express sentiment towards the airline mentioned in the tweet.\n",
        "\n"
      ],
      "metadata": {
        "id": "jZJ4QfGlHIYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Load the selected data set and display the first seven data."
      ],
      "metadata": {
        "id": "d2eBii9BHrQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "df = pd.read_csv(\"Tweets.csv\")\n",
        "\n",
        "# Display the first seven rows of the dataset\n",
        "print(df.head(7))"
      ],
      "metadata": {
        "id": "JzPhjxt2Ua2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5006316-d380-4c41-b66e-9d4cdf3394d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
            "0  570306133677760513           neutral                        1.0000   \n",
            "1  570301130888122368          positive                        0.3486   \n",
            "2  570301083672813571           neutral                        0.6837   \n",
            "3  570301031407624196          negative                        1.0000   \n",
            "4  570300817074462722          negative                        1.0000   \n",
            "5  570300767074181121          negative                        1.0000   \n",
            "6  570300616901320704          positive                        0.6745   \n",
            "\n",
            "  negativereason  negativereason_confidence         airline  \\\n",
            "0            NaN                        NaN  Virgin America   \n",
            "1            NaN                     0.0000  Virgin America   \n",
            "2            NaN                        NaN  Virgin America   \n",
            "3     Bad Flight                     0.7033  Virgin America   \n",
            "4     Can't Tell                     1.0000  Virgin America   \n",
            "5     Can't Tell                     0.6842  Virgin America   \n",
            "6            NaN                     0.0000  Virgin America   \n",
            "\n",
            "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
            "0                    NaN     cairdin                 NaN              0   \n",
            "1                    NaN    jnardino                 NaN              0   \n",
            "2                    NaN  yvonnalynn                 NaN              0   \n",
            "3                    NaN    jnardino                 NaN              0   \n",
            "4                    NaN    jnardino                 NaN              0   \n",
            "5                    NaN    jnardino                 NaN              0   \n",
            "6                    NaN  cjmcginnis                 NaN              0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0                @VirginAmerica What @dhepburn said.         NaN   \n",
            "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
            "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
            "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
            "5  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
            "6  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
            "\n",
            "               tweet_created    tweet_location               user_timezone  \n",
            "0  2015-02-24 11:35:52 -0800               NaN  Eastern Time (US & Canada)  \n",
            "1  2015-02-24 11:15:59 -0800               NaN  Pacific Time (US & Canada)  \n",
            "2  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)  \n",
            "3  2015-02-24 11:15:36 -0800               NaN  Pacific Time (US & Canada)  \n",
            "4  2015-02-24 11:14:45 -0800               NaN  Pacific Time (US & Canada)  \n",
            "5  2015-02-24 11:14:33 -0800               NaN  Pacific Time (US & Canada)  \n",
            "6  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Load the selected data set and display the first seven data."
      ],
      "metadata": {
        "id": "Lu0-vtpjnx4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTflYbbeIXJp",
        "outputId": "70ce9a28-570f-4ddb-cd38-eb31dbeb66bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSXBydnWug54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c1b9ae-3cb6-42e8-eb8e-38d3fd92e947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2b452c0dd758>:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df[\"text\"] = df[\"text\"].str.replace('[^\\w\\s]','')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  airline_sentiment negativereason         airline airline_sentiment_gold  \\\n",
            "0           neutral            NaN  Virgin America                    NaN   \n",
            "1          positive            NaN  Virgin America                    NaN   \n",
            "2           neutral            NaN  Virgin America                    NaN   \n",
            "3          negative     Bad Flight  Virgin America                    NaN   \n",
            "4          negative     Can't Tell  Virgin America                    NaN   \n",
            "5          negative     Can't Tell  Virgin America                    NaN   \n",
            "6          positive            NaN  Virgin America                    NaN   \n",
            "\n",
            "         name negativereason_gold  retweet_count  \\\n",
            "0     cairdin                 NaN              0   \n",
            "1    jnardino                 NaN              0   \n",
            "2  yvonnalynn                 NaN              0   \n",
            "3    jnardino                 NaN              0   \n",
            "4    jnardino                 NaN              0   \n",
            "5    jnardino                 NaN              0   \n",
            "6  cjmcginnis                 NaN              0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0                                         what  said         NaN   \n",
            "1   plus youve added commercials to the experienc...         NaN   \n",
            "2   i didnt today must mean i need to take anothe...         NaN   \n",
            "3   its really aggressive to blast obnoxious ente...         NaN   \n",
            "4            and its a really big bad thing about it         NaN   \n",
            "5   seriously would pay 30 a flight for seats tha...         NaN   \n",
            "6   yes nearly every time i fly vx this ear worm ...         NaN   \n",
            "\n",
            "               tweet_created    tweet_location               user_timezone  \\\n",
            "0  2015-02-24 11:35:52 -0800               NaN  Eastern Time (US & Canada)   \n",
            "1  2015-02-24 11:15:59 -0800               NaN  Pacific Time (US & Canada)   \n",
            "2  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)   \n",
            "3  2015-02-24 11:15:36 -0800               NaN  Pacific Time (US & Canada)   \n",
            "4  2015-02-24 11:14:45 -0800               NaN  Pacific Time (US & Canada)   \n",
            "5  2015-02-24 11:14:33 -0800               NaN  Pacific Time (US & Canada)   \n",
            "6  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)   \n",
            "\n",
            "                                              tokens  \n",
            "0                                             [said]  \n",
            "1  [plus, youve, added, commercials, experience, ...  \n",
            "2  [didnt, today, must, mean, need, take, another...  \n",
            "3  [really, aggressive, blast, obnoxious, enterta...  \n",
            "4                          [really, big, bad, thing]  \n",
            "5  [seriously, would, pay, 30, flight, seats, did...  \n",
            "6  [yes, nearly, every, time, fly, vx, ear, worm,...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "df = pd.read_csv(\"Tweets.csv\")\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df = df.drop(columns=[\"tweet_id\", \"airline_sentiment_confidence\", \"negativereason_confidence\"])\n",
        "\n",
        "# Convert tweet text to lowercase\n",
        "df[\"text\"] = df[\"text\"].str.lower()\n",
        "\n",
        "# Remove URLs, mentions, and hashtags\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r\"@\\S+\", \"\", x))\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r\"#\\S+\", \"\", x))\n",
        "\n",
        "# Remove punctuation and special characters\n",
        "df[\"text\"] = df[\"text\"].str.replace('[^\\w\\s]','')\n",
        "\n",
        "# Tokenize tweet text\n",
        "df[\"tokens\"] = df[\"text\"].apply(lambda x: word_tokenize(x))\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [word for word in x if not word in stop_words])\n",
        "\n",
        "# Display the pre-processed data\n",
        "print(df.head(7))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Teach a model using one of the methods learned in the lesson."
      ],
      "metadata": {
        "id": "p0X5U6AuJKnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"airline_sentiment\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to a numerical feature matrix\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "jIKI6gCKJKW1",
        "outputId": "4920eb6b-f530-46eb-b054-1e66a45dd9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) Evaluate the model."
      ],
      "metadata": {
        "id": "ZAgm8sciJysT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate the model and print the metrics\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqxWoqNPJy1L",
        "outputId": "683fb8fb-ceb6-4b65-bcac-b38fc40b38a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7831284153005464\n",
            "Precision: 0.7813394088706034\n",
            "Recall: 0.7831284153005464\n",
            "F1 score: 0.7602611600675673\n"
          ]
        }
      ]
    }
  ]
}